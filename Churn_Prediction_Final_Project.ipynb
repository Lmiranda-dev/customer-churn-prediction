{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLUuzKYjzBfW",
        "outputId": "e6e516b5-5117-4c8c-ed1f-e2abd0dd585a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded successfully as telco_customer_churn.csv\n"
          ]
        }
      ],
      "source": [
        "# To download dataset\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\"\n",
        "filename = \"telco_customer_churn.csv\"\n",
        "\n",
        "try:\n",
        "    urllib.request.urlretrieve(url, filename)\n",
        "    print(f\"Dataset downloaded successfully as {filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"Download failed: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Customer Churn Prediction using PySpark ML - FINAL VERSION\n",
        "# This version handles missing dataset files automatically\n",
        "\n",
        "# Import required libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "from functools import reduce\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"CustomerChurnPrediction\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Spark session initialized successfully!\")\n",
        "\n",
        "# DATASET LOADING WITH MULTIPLE FALLBACK OPTIONS\n",
        "print(\"Attempting to load dataset...\")\n",
        "\n",
        "try:\n",
        "    # Method 1: Try to load from local file\n",
        "    df = spark.read.csv(\"telco_customer_churn.csv\", header=True, inferSchema=True)\n",
        "    print(\"✓ Dataset loaded from local file\")\n",
        "except:\n",
        "    print(\"Local file not found. Trying alternative methods...\")\n",
        "\n",
        "    try:\n",
        "        # Method 2: Try to download from URL\n",
        "        import urllib.request\n",
        "        print(\"Downloading dataset from URL...\")\n",
        "        url = \"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\"\n",
        "        urllib.request.urlretrieve(url, \"telco_customer_churn.csv\")\n",
        "        df = spark.read.csv(\"telco_customer_churn.csv\", header=True, inferSchema=True)\n",
        "        print(\"✓ Dataset downloaded and loaded successfully\")\n",
        "    except Exception as e:\n",
        "        print(\"Download failed. Creating realistic sample dataset for demonstration...\")\n",
        "\n",
        "        # This method is only if the other two fail.\n",
        "        # Method 3: Create sample dataset with realistic patterns\n",
        "        from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
        "        import random\n",
        "\n",
        "        # Define schema\n",
        "        schema = StructType([\n",
        "            StructField(\"customerID\", StringType(), True),\n",
        "            StructField(\"gender\", StringType(), True),\n",
        "            StructField(\"SeniorCitizen\", IntegerType(), True),\n",
        "            StructField(\"Partner\", StringType(), True),\n",
        "            StructField(\"Dependents\", StringType(), True),\n",
        "            StructField(\"tenure\", IntegerType(), True),\n",
        "            StructField(\"PhoneService\", StringType(), True),\n",
        "            StructField(\"MultipleLines\", StringType(), True),\n",
        "            StructField(\"InternetService\", StringType(), True),\n",
        "            StructField(\"OnlineSecurity\", StringType(), True),\n",
        "            StructField(\"OnlineBackup\", StringType(), True),\n",
        "            StructField(\"DeviceProtection\", StringType(), True),\n",
        "            StructField(\"TechSupport\", StringType(), True),\n",
        "            StructField(\"StreamingTV\", StringType(), True),\n",
        "            StructField(\"StreamingMovies\", StringType(), True),\n",
        "            StructField(\"Contract\", StringType(), True),\n",
        "            StructField(\"PaperlessBilling\", StringType(), True),\n",
        "            StructField(\"PaymentMethod\", StringType(), True),\n",
        "            StructField(\"MonthlyCharges\", DoubleType(), True),\n",
        "            StructField(\"TotalCharges\", StringType(), True),\n",
        "            StructField(\"Churn\", StringType(), True)\n",
        "        ])\n",
        "\n",
        "        # Create realistic sample data\n",
        "        print(\"Generating sample data with realistic churn patterns...\")\n",
        "        sample_data = []\n",
        "        contracts = [\"Month-to-month\", \"One year\", \"Two year\"]\n",
        "        payments = [\"Electronic check\", \"Mailed check\", \"Bank transfer (automatic)\", \"Credit card (automatic)\"]\n",
        "        internet_services = [\"DSL\", \"Fiber optic\", \"No\"]\n",
        "        yes_no = [\"Yes\", \"No\"]\n",
        "        yes_no_no_service = [\"Yes\", \"No\", \"No internet service\"]\n",
        "\n",
        "        random.seed(42)  # For reproducible results\n",
        "\n",
        "        for i in range(7043):  # Match original dataset size\n",
        "            tenure = random.randint(1, 72)\n",
        "            monthly_charges = round(random.uniform(18.25, 118.75), 2)\n",
        "            contract = random.choice(contracts)\n",
        "\n",
        "            # Create realistic churn patterns based on contract type\n",
        "            if contract == \"Month-to-month\":\n",
        "                churn_prob = 0.427\n",
        "            elif contract == \"One year\":\n",
        "                churn_prob = 0.113\n",
        "            else:  # Two year\n",
        "                churn_prob = 0.028\n",
        "\n",
        "            churn = \"Yes\" if random.random() < churn_prob else \"No\"\n",
        "\n",
        "            # Generate total charges (some missing values like real dataset)\n",
        "            if random.random() < 0.0015:  # 0.15% missing like real data\n",
        "                total_charges = \" \"\n",
        "            else:\n",
        "                total_charges = str(round(tenure * monthly_charges + random.uniform(-100, 500), 2))\n",
        "\n",
        "            row = (\n",
        "                f\"7590-VHVEG-{i:04d}\",\n",
        "                random.choice([\"Male\", \"Female\"]),\n",
        "                random.choice([0, 1]) if random.random() < 0.16 else 0,  # 16% senior citizens\n",
        "                random.choice(yes_no),\n",
        "                random.choice(yes_no),\n",
        "                tenure,\n",
        "                random.choice(yes_no),\n",
        "                random.choice([\"No\", \"Yes\", \"No phone service\"]),\n",
        "                random.choice(internet_services),\n",
        "                random.choice(yes_no_no_service),\n",
        "                random.choice(yes_no_no_service),\n",
        "                random.choice(yes_no_no_service),\n",
        "                random.choice(yes_no_no_service),\n",
        "                random.choice(yes_no_no_service),\n",
        "                random.choice(yes_no_no_service),\n",
        "                contract,\n",
        "                random.choice(yes_no),\n",
        "                random.choice(payments),\n",
        "                monthly_charges,\n",
        "                total_charges,\n",
        "                churn\n",
        "            )\n",
        "            sample_data.append(row)\n",
        "\n",
        "        df = spark.createDataFrame(sample_data, schema)\n",
        "        print(\"✓ Sample dataset created successfully (7,043 records)\")\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATASET INFORMATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Dataset Shape: {df.count()} rows, {len(df.columns)} columns\")\n",
        "\n",
        "print(\"\\nDataset Schema:\")\n",
        "df.printSchema()\n",
        "\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "df.show(5)\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values Analysis:\")\n",
        "missing_counts = df.select([count(when(col(c).isNull() | (col(c) == \" \"), c)).alias(c) for c in df.columns])\n",
        "missing_counts.show()\n",
        "\n",
        "# Data Preprocessing\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Handle missing values in TotalCharges\n",
        "print(\"Handling missing values in TotalCharges...\")\n",
        "df = df.withColumn(\"TotalCharges\",\n",
        "                   when(col(\"TotalCharges\") == \" \", 0.0)\n",
        "                   .otherwise(col(\"TotalCharges\").cast(\"double\")))\n",
        "\n",
        "# Convert Churn to binary\n",
        "print(\"Converting Churn to binary format...\")\n",
        "df = df.withColumn(\"ChurnLabel\", when(col(\"Churn\") == \"Yes\", 1).otherwise(0))\n",
        "\n",
        "# Feature Engineering\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURE ENGINEERING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create tenure groups\n",
        "print(\"Creating tenure groups...\")\n",
        "df = df.withColumn(\"TenureGroup\",\n",
        "                   when(col(\"tenure\") <= 12, \"0-12 months\")\n",
        "                   .when(col(\"tenure\") <= 24, \"12-24 months\")\n",
        "                   .when(col(\"tenure\") <= 48, \"24-48 months\")\n",
        "                   .otherwise(\"48+ months\"))\n",
        "\n",
        "# Service columns for counting\n",
        "service_cols = [\"PhoneService\", \"MultipleLines\", \"InternetService\",\n",
        "                \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\",\n",
        "                \"TechSupport\", \"StreamingTV\", \"StreamingMovies\"]\n",
        "\n",
        "# Count active services using proper PySpark syntax\n",
        "print(\"Calculating total services per customer...\")\n",
        "service_conditions = [when(col(c) == \"Yes\", 1).otherwise(0) for c in service_cols]\n",
        "df = df.withColumn(\"TotalServices\", reduce(lambda a, b: a + b, service_conditions))\n",
        "\n",
        "# Create monthly charges per service ratio\n",
        "print(\"Creating charges per service ratio...\")\n",
        "df = df.withColumn(\"ChargesPerService\",\n",
        "                   when(col(\"TotalServices\") > 0, col(\"MonthlyCharges\") / col(\"TotalServices\"))\n",
        "                   .otherwise(col(\"MonthlyCharges\")))\n",
        "\n",
        "# Exploratory Data Analysis\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EXPLORATORY DATA ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"Churn Distribution:\")\n",
        "churn_dist = df.groupBy(\"Churn\").count().orderBy(\"Churn\")\n",
        "churn_dist.show()\n",
        "\n",
        "print(\"Churn Rate by Contract Type:\")\n",
        "contract_analysis = df.groupBy(\"Contract\") \\\n",
        "                     .agg(count(\"*\").alias(\"total_customers\"),\n",
        "                          sum(\"ChurnLabel\").alias(\"churned_customers\"),\n",
        "                          avg(\"ChurnLabel\").alias(\"churn_rate\")) \\\n",
        "                     .orderBy(desc(\"churn_rate\"))\n",
        "contract_analysis.show()\n",
        "\n",
        "print(\"Churn Rate by Tenure Group:\")\n",
        "tenure_analysis = df.groupBy(\"TenureGroup\") \\\n",
        "                   .agg(count(\"*\").alias(\"total_customers\"),\n",
        "                        avg(\"ChurnLabel\").alias(\"churn_rate\")) \\\n",
        "                   .orderBy(\"churn_rate\")\n",
        "tenure_analysis.show()\n",
        "\n",
        "# Prepare features for ML\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MACHINE LEARNING PIPELINE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Categorical columns to be indexed\n",
        "categorical_cols = [\"gender\", \"SeniorCitizen\", \"Partner\", \"Dependents\",\n",
        "                   \"PhoneService\", \"MultipleLines\", \"InternetService\",\n",
        "                   \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\",\n",
        "                   \"TechSupport\", \"StreamingTV\", \"StreamingMovies\",\n",
        "                   \"Contract\", \"PaperlessBilling\", \"PaymentMethod\", \"TenureGroup\"]\n",
        "\n",
        "# Numerical columns\n",
        "numerical_cols = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\",\n",
        "                 \"TotalServices\", \"ChargesPerService\"]\n",
        "\n",
        "print(f\"Categorical features: {len(categorical_cols)}\")\n",
        "print(f\"Numerical features: {len(numerical_cols)}\")\n",
        "\n",
        "# String Indexing for categorical variables\n",
        "print(\"Creating string indexers for categorical variables...\")\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_indexed\",\n",
        "                         handleInvalid=\"skip\") for col in categorical_cols]\n",
        "\n",
        "# Create feature vector\n",
        "feature_cols = [col+\"_indexed\" for col in categorical_cols] + numerical_cols\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
        "\n",
        "# Split data\n",
        "print(\"Splitting data into training and testing sets...\")\n",
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(f\"Training set size: {train_df.count()}\")\n",
        "print(f\"Test set size: {test_df.count()}\")\n",
        "\n",
        "# Model Development\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Model 1: Logistic Regression\n",
        "print(\"Setting up Logistic Regression model...\")\n",
        "lr = LogisticRegression(featuresCol=\"scaledFeatures\", labelCol=\"ChurnLabel\",\n",
        "                       maxIter=100, regParam=0.01)\n",
        "\n",
        "# Model 2: Random Forest\n",
        "print(\"Setting up Random Forest model...\")\n",
        "rf = RandomForestClassifier(featuresCol=\"scaledFeatures\", labelCol=\"ChurnLabel\",\n",
        "                           numTrees=50, maxDepth=10, seed=42)\n",
        "\n",
        "# Create pipelines\n",
        "lr_pipeline = Pipeline(stages=indexers + [assembler, scaler, lr])\n",
        "rf_pipeline = Pipeline(stages=indexers + [assembler, scaler, rf])\n",
        "\n",
        "# Train models\n",
        "print(\"Training Logistic Regression model...\")\n",
        "lr_model = lr_pipeline.fit(train_df)\n",
        "\n",
        "print(\"Training Random Forest model...\")\n",
        "rf_model = rf_pipeline.fit(train_df)\n",
        "\n",
        "# Make predictions\n",
        "print(\"Making predictions on test set...\")\n",
        "lr_predictions = lr_model.transform(test_df)\n",
        "rf_predictions = rf_model.transform(test_df)\n",
        "\n",
        "# Model Evaluation\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Initialize evaluators\n",
        "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"ChurnLabel\",\n",
        "                                                rawPredictionCol=\"rawPrediction\")\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"ChurnLabel\",\n",
        "                                                   predictionCol=\"prediction\")\n",
        "\n",
        "# Logistic Regression Results\n",
        "print(\"Evaluating Logistic Regression...\")\n",
        "lr_auc = binary_evaluator.evaluate(lr_predictions, {binary_evaluator.metricName: \"areaUnderROC\"})\n",
        "lr_accuracy = multi_evaluator.evaluate(lr_predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "lr_precision = multi_evaluator.evaluate(lr_predictions, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
        "lr_recall = multi_evaluator.evaluate(lr_predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "lr_f1 = multi_evaluator.evaluate(lr_predictions, {multi_evaluator.metricName: \"f1\"})\n",
        "\n",
        "# Random Forest Results\n",
        "print(\"Evaluating Random Forest...\")\n",
        "rf_auc = binary_evaluator.evaluate(rf_predictions, {binary_evaluator.metricName: \"areaUnderROC\"})\n",
        "rf_accuracy = multi_evaluator.evaluate(rf_predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
        "rf_precision = multi_evaluator.evaluate(rf_predictions, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
        "rf_recall = multi_evaluator.evaluate(rf_predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
        "rf_f1 = multi_evaluator.evaluate(rf_predictions, {multi_evaluator.metricName: \"f1\"})\n",
        "\n",
        "# Print Results\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL PERFORMANCE COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Metric':<20} {'Logistic Regression':<25} {'Random Forest':<20}\")\n",
        "print(\"-\"*70)\n",
        "print(f\"{'AUC-ROC':<20} {lr_auc:<25.4f} {rf_auc:<20.4f}\")\n",
        "print(f\"{'Accuracy':<20} {lr_accuracy:<25.4f} {rf_accuracy:<20.4f}\")\n",
        "print(f\"{'Precision':<20} {lr_precision:<25.4f} {rf_precision:<20.4f}\")\n",
        "print(f\"{'Recall':<20} {lr_recall:<25.4f} {rf_recall:<20.4f}\")\n",
        "print(f\"{'F1-Score':<20} {lr_f1:<25.4f} {rf_f1:<20.4f}\")\n",
        "\n",
        "# Feature Importance Analysis\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get feature importance from Random Forest\n",
        "feature_importance = rf_model.stages[-1].featureImportances\n",
        "feature_names = feature_cols\n",
        "\n",
        "# Create feature importance analysis\n",
        "importance_list = [(feature_names[i], float(feature_importance[i]))\n",
        "                  for i in range(len(feature_names))]\n",
        "importance_sorted = sorted(importance_list, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"Top 10 Most Important Features (Random Forest):\")\n",
        "print(f\"{'Feature':<25} {'Importance':<15}\")\n",
        "print(\"-\"*40)\n",
        "for feature, importance in importance_sorted[:10]:\n",
        "    print(f\"{feature:<25} {importance:<15.4f}\")\n",
        "\n",
        "# Business Impact Analysis\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BUSINESS IMPACT ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Analyze high-risk segments\n",
        "print(\"High-Risk Customer Segments:\")\n",
        "high_risk_segments = df.groupBy(\"Contract\", \"PaymentMethod\") \\\n",
        "                      .agg(count(\"*\").alias(\"customers\"),\n",
        "                           avg(\"ChurnLabel\").alias(\"churn_rate\"),\n",
        "                           avg(\"MonthlyCharges\").alias(\"avg_monthly_charges\")) \\\n",
        "                      .filter(col(\"customers\") > 50) \\\n",
        "                      .orderBy(desc(\"churn_rate\"))\n",
        "\n",
        "high_risk_segments.show(10)\n",
        "\n",
        "# Revenue analysis\n",
        "churned_customers = df.filter(col(\"ChurnLabel\") == 1)\n",
        "total_customers = df.count()\n",
        "churned_count = churned_customers.count()\n",
        "\n",
        "revenue_metrics = churned_customers.agg(\n",
        "    sum(\"MonthlyCharges\").alias(\"monthly_revenue_lost\"),\n",
        "    avg(\"MonthlyCharges\").alias(\"avg_customer_value\"),\n",
        "    sum(\"TotalCharges\").alias(\"total_revenue_lost\")\n",
        ").collect()[0]\n",
        "\n",
        "print(f\"\\nRevenue Impact Summary:\")\n",
        "print(f\"Total Customers: {total_customers:,}\")\n",
        "print(f\"Churned Customers: {churned_count:,}\")\n",
        "print(f\"Churn Rate: {(churned_count/total_customers)*100:.1f}%\")\n",
        "print(f\"Monthly Revenue Lost: ${revenue_metrics['monthly_revenue_lost']:,.2f}\")\n",
        "print(f\"Annual Revenue at Risk: ${revenue_metrics['monthly_revenue_lost']*12:,.2f}\")\n",
        "print(f\"Average Churned Customer Value: ${revenue_metrics['avg_customer_value']:.2f}\")\n",
        "\n",
        "# Model Performance in Business Terms\n",
        "test_size = test_df.count()\n",
        "rf_predictions_pd = rf_predictions.select(\"ChurnLabel\", \"prediction\").toPandas()\n",
        "\n",
        "# Confusion matrix values\n",
        "true_positives = len(rf_predictions_pd[(rf_predictions_pd['ChurnLabel'] == 1) & (rf_predictions_pd['prediction'] == 1)])\n",
        "false_negatives = len(rf_predictions_pd[(rf_predictions_pd['ChurnLabel'] == 1) & (rf_predictions_pd['prediction'] == 0)])\n",
        "true_negatives = len(rf_predictions_pd[(rf_predictions_pd['ChurnLabel'] == 0) & (rf_predictions_pd['prediction'] == 0)])\n",
        "false_positives = len(rf_predictions_pd[(rf_predictions_pd['ChurnLabel'] == 0) & (rf_predictions_pd['prediction'] == 1)])\n",
        "\n",
        "print(f\"\\nModel Performance in Business Terms:\")\n",
        "print(f\"Correctly Identified Churners: {true_positives}\")\n",
        "print(f\"Missed Churners: {false_negatives}\")\n",
        "print(f\"False Alarms: {false_positives}\")\n",
        "print(f\"Correctly Identified Loyal Customers: {true_negatives}\")\n",
        "\n",
        "# Calculate potential savings\n",
        "avg_monthly_value = revenue_metrics['avg_customer_value']\n",
        "if true_positives > 0:\n",
        "    potential_monthly_savings = true_positives * avg_monthly_value * 0.5  # Assume 50% retention success\n",
        "    potential_annual_savings = potential_monthly_savings * 12\n",
        "    print(f\"\\nPotential Business Impact (50% retention success rate):\")\n",
        "    print(f\"Monthly Revenue Savings: ${potential_monthly_savings:,.2f}\")\n",
        "    print(f\"Annual Revenue Savings: ${potential_annual_savings:,.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*60)\n",
        "print(\"✓ Models trained and evaluated\")\n",
        "print(\"✓ Feature importance analyzed\")\n",
        "print(\"✓ Business impact calculated\")\n",
        "print(\"✓ Results ready for reporting\")\n",
        "\n",
        "# Clean up\n",
        "spark.stop()\n",
        "print(\"\\nSpark session stopped.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LUm0mHF0Yds",
        "outputId": "1c6e2b2c-d37b-41c7-b964-7b0b6378f5f4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark session initialized successfully!\n",
            "Attempting to load dataset...\n",
            "Local file not found. Trying alternative methods...\n",
            "Downloading dataset from URL...\n",
            "✓ Dataset downloaded and loaded successfully\n",
            "\n",
            "============================================================\n",
            "DATASET INFORMATION\n",
            "============================================================\n",
            "Dataset Shape: 7043 rows, 21 columns\n",
            "\n",
            "Dataset Schema:\n",
            "root\n",
            " |-- customerID: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- SeniorCitizen: integer (nullable = true)\n",
            " |-- Partner: string (nullable = true)\n",
            " |-- Dependents: string (nullable = true)\n",
            " |-- tenure: integer (nullable = true)\n",
            " |-- PhoneService: string (nullable = true)\n",
            " |-- MultipleLines: string (nullable = true)\n",
            " |-- InternetService: string (nullable = true)\n",
            " |-- OnlineSecurity: string (nullable = true)\n",
            " |-- OnlineBackup: string (nullable = true)\n",
            " |-- DeviceProtection: string (nullable = true)\n",
            " |-- TechSupport: string (nullable = true)\n",
            " |-- StreamingTV: string (nullable = true)\n",
            " |-- StreamingMovies: string (nullable = true)\n",
            " |-- Contract: string (nullable = true)\n",
            " |-- PaperlessBilling: string (nullable = true)\n",
            " |-- PaymentMethod: string (nullable = true)\n",
            " |-- MonthlyCharges: double (nullable = true)\n",
            " |-- TotalCharges: string (nullable = true)\n",
            " |-- Churn: string (nullable = true)\n",
            "\n",
            "\n",
            "First 5 rows:\n",
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
            "|customerID|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|   MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|       PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
            "|7590-VHVEG|Female|            0|    Yes|        No|     1|          No|No phone service|            DSL|            No|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|         29.85|       29.85|   No|\n",
            "|5575-GNVDE|  Male|            0|     No|        No|    34|         Yes|              No|            DSL|           Yes|          No|             Yes|         No|         No|             No|      One year|              No|        Mailed check|         56.95|      1889.5|   No|\n",
            "|3668-QPYBK|  Male|            0|     No|        No|     2|         Yes|              No|            DSL|           Yes|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|        Mailed check|         53.85|      108.15|  Yes|\n",
            "|7795-CFOCW|  Male|            0|     No|        No|    45|          No|No phone service|            DSL|           Yes|          No|             Yes|        Yes|         No|             No|      One year|              No|Bank transfer (au...|          42.3|     1840.75|   No|\n",
            "|9237-HQITU|Female|            0|     No|        No|     2|         Yes|              No|    Fiber optic|            No|          No|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|          70.7|      151.65|  Yes|\n",
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Missing Values Analysis:\n",
            "+----------+------+-------------+-------+----------+------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------+----------------+-------------+--------------+------------+-----+\n",
            "|customerID|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|Contract|PaperlessBilling|PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
            "+----------+------+-------------+-------+----------+------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------+----------------+-------------+--------------+------------+-----+\n",
            "|         0|     0|            0|      0|         0|     0|           0|            0|              0|             0|           0|               0|          0|          0|              0|       0|               0|            0|             0|          11|    0|\n",
            "+----------+------+-------------+-------+----------+------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------+----------------+-------------+--------------+------------+-----+\n",
            "\n",
            "\n",
            "============================================================\n",
            "DATA PREPROCESSING\n",
            "============================================================\n",
            "Handling missing values in TotalCharges...\n",
            "Converting Churn to binary format...\n",
            "\n",
            "============================================================\n",
            "FEATURE ENGINEERING\n",
            "============================================================\n",
            "Creating tenure groups...\n",
            "Calculating total services per customer...\n",
            "Creating charges per service ratio...\n",
            "\n",
            "============================================================\n",
            "EXPLORATORY DATA ANALYSIS\n",
            "============================================================\n",
            "Churn Distribution:\n",
            "+-----+-----+\n",
            "|Churn|count|\n",
            "+-----+-----+\n",
            "|   No| 5174|\n",
            "|  Yes| 1869|\n",
            "+-----+-----+\n",
            "\n",
            "Churn Rate by Contract Type:\n",
            "+--------------+---------------+-----------------+-------------------+\n",
            "|      Contract|total_customers|churned_customers|         churn_rate|\n",
            "+--------------+---------------+-----------------+-------------------+\n",
            "|Month-to-month|           3875|             1655| 0.4270967741935484|\n",
            "|      One year|           1473|              166|0.11269517990495587|\n",
            "|      Two year|           1695|               48|0.02831858407079646|\n",
            "+--------------+---------------+-----------------+-------------------+\n",
            "\n",
            "Churn Rate by Tenure Group:\n",
            "+------------+---------------+-------------------+\n",
            "| TenureGroup|total_customers|         churn_rate|\n",
            "+------------+---------------+-------------------+\n",
            "|  48+ months|           2239|0.09513175524787852|\n",
            "|24-48 months|           1594| 0.2038895859473024|\n",
            "|12-24 months|           1024|        0.287109375|\n",
            "| 0-12 months|           2186|0.47438243366880145|\n",
            "+------------+---------------+-------------------+\n",
            "\n",
            "\n",
            "============================================================\n",
            "MACHINE LEARNING PIPELINE\n",
            "============================================================\n",
            "Categorical features: 17\n",
            "Numerical features: 5\n",
            "Creating string indexers for categorical variables...\n",
            "Splitting data into training and testing sets...\n",
            "Training set size: 5698\n",
            "Test set size: 1345\n",
            "\n",
            "============================================================\n",
            "MODEL TRAINING\n",
            "============================================================\n",
            "Setting up Logistic Regression model...\n",
            "Setting up Random Forest model...\n",
            "Training Logistic Regression model...\n",
            "Training Random Forest model...\n",
            "Making predictions on test set...\n",
            "\n",
            "============================================================\n",
            "MODEL EVALUATION\n",
            "============================================================\n",
            "Evaluating Logistic Regression...\n",
            "Evaluating Random Forest...\n",
            "\n",
            "======================================================================\n",
            "MODEL PERFORMANCE COMPARISON\n",
            "======================================================================\n",
            "Metric               Logistic Regression       Random Forest       \n",
            "----------------------------------------------------------------------\n",
            "AUC-ROC              0.8382                    0.8373              \n",
            "Accuracy             0.7985                    0.7911              \n",
            "Precision            0.7875                    0.7798              \n",
            "Recall               0.7985                    0.7911              \n",
            "F1-Score             0.7867                    0.7810              \n",
            "\n",
            "============================================================\n",
            "FEATURE IMPORTANCE ANALYSIS\n",
            "============================================================\n",
            "Top 10 Most Important Features (Random Forest):\n",
            "Feature                   Importance     \n",
            "----------------------------------------\n",
            "Contract_indexed          0.1630         \n",
            "tenure                    0.1452         \n",
            "ChargesPerService         0.0987         \n",
            "TotalCharges              0.0901         \n",
            "MonthlyCharges            0.0727         \n",
            "PaymentMethod_indexed     0.0582         \n",
            "InternetService_indexed   0.0531         \n",
            "OnlineSecurity_indexed    0.0475         \n",
            "TechSupport_indexed       0.0413         \n",
            "TenureGroup_indexed       0.0340         \n",
            "\n",
            "============================================================\n",
            "BUSINESS IMPACT ANALYSIS\n",
            "============================================================\n",
            "High-Risk Customer Segments:\n",
            "+--------------+--------------------+---------+-------------------+-------------------+\n",
            "|      Contract|       PaymentMethod|customers|         churn_rate|avg_monthly_charges|\n",
            "+--------------+--------------------+---------+-------------------+-------------------+\n",
            "|Month-to-month|    Electronic check|     1850| 0.5372972972972972|  74.98948648648656|\n",
            "|Month-to-month|Bank transfer (au...|      589|0.34125636672325976|  69.08539898132436|\n",
            "|Month-to-month|Credit card (auto...|      543| 0.3278084714548803|  67.67882136279928|\n",
            "|Month-to-month|        Mailed check|      893| 0.3157894736842105| 46.050055991041496|\n",
            "|      One year|    Electronic check|      347| 0.1844380403458213|  79.09524495677235|\n",
            "|      One year|Credit card (auto...|      398|0.10301507537688442|  67.97236180904528|\n",
            "|      One year|Bank transfer (au...|      391|0.09718670076726342|  67.48414322250639|\n",
            "|      Two year|    Electronic check|      168|0.07738095238095238|  84.33571428571433|\n",
            "|      One year|        Mailed check|      337|0.06824925816023739|  44.30637982195845|\n",
            "|      Two year|Bank transfer (au...|      564|0.03368794326241135|  65.01391843971636|\n",
            "+--------------+--------------------+---------+-------------------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "\n",
            "Revenue Impact Summary:\n",
            "Total Customers: 7,043\n",
            "Churned Customers: 1,869\n",
            "Churn Rate: 26.5%\n",
            "Monthly Revenue Lost: $139,130.85\n",
            "Annual Revenue at Risk: $1,669,570.20\n",
            "Average Churned Customer Value: $74.44\n",
            "\n",
            "Model Performance in Business Terms:\n",
            "Correctly Identified Churners: 183\n",
            "Missed Churners: 186\n",
            "False Alarms: 95\n",
            "Correctly Identified Loyal Customers: 881\n",
            "\n",
            "Potential Business Impact (50% retention success rate):\n",
            "Monthly Revenue Savings: $6,811.38\n",
            "Annual Revenue Savings: $81,736.58\n",
            "\n",
            "============================================================\n",
            "ANALYSIS COMPLETED SUCCESSFULLY!\n",
            "============================================================\n",
            "✓ Models trained and evaluated\n",
            "✓ Feature importance analyzed\n",
            "✓ Business impact calculated\n",
            "✓ Results ready for reporting\n",
            "\n",
            "Spark session stopped.\n"
          ]
        }
      ]
    }
  ]
}